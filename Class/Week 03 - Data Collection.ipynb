{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "Data Collection is an important process leading to understanding how to get data, how to clean and prepare data for data science applications. This notebook will demonstrate some methods that can be used to gather and clean data. \n",
    "\n",
    "This notebook demonstrate multiple ways that we can collect data. \n",
    "Ways that you can get data\n",
    "1. government/state sources - https://www.data.gov/  https://opendata.cityofnewyork.us/data/\n",
    "2. database queries - using SQL\n",
    "3. data feeds from instruments/senses\n",
    "4. API - web-based calls using autheticated calls to get data\n",
    "5. scraping data (legally) - https://apnews.com/article/1e1cacd92df74f48846e8bce5237b97d\n",
    "\n",
    "Most data are unstructred and requires extensive processing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data from URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# COVID-19 Hospital Data Coverage Detail\n",
    "url ='https://healthdata.gov/api/views/ieks-f4qs/rows.csv?accessType=DOWNLOAD'\n",
    "df = pd.read_csv(url, delimiter=',', quotechar='\"')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Databases\n",
    "\n",
    "SQLite is a C-language library that implements a small, fast, self-contained, high-reliability, full-featured, SQL database engine. SQLite is the most used database engine in the world. SQLite is built into all mobile phones and most computers and comes bundled inside countless other applications that people use every day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "connection = sqlite3.connect(\"publisher2.db\")\n",
    "# Allows Python code to execute PostgreSQL command in a database session. \n",
    "# Cursors are created by the connection.cursor() method: they are bound to the connection \n",
    "# for the entire lifetime and all the commands are executed in the context of the database \n",
    "# session wrapped by the connection.\n",
    "cursor = connection.cursor()\n",
    "# do your stuff\n",
    "#connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a database operation (query or command).\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE publisher2 (\n",
    "id INTEGER PRIMARY KEY,\n",
    "name TEXT\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the table:\n",
    "cursor.execute(\"INSERT INTO publisher2 VALUES (1, 'Pearson Press')\")\n",
    "cursor.execute(\"INSERT INTO publisher2 VALUES (2, 'MIT Press')\")\n",
    "cursor.execute(\"INSERT INTO publisher2 VALUES (3, 'Cambridge Press')\")\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete item\n",
    "cursor.execute(\"DELETE FROM publisher2 WHERE id == 3\")\n",
    "conn = sqlite3.connect(\"publisher2\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query data\n",
    "for row in cursor.execute('SELECT * FROM publisher2'):\n",
    "  print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read table directly into a Pandas DataFrame:\n",
    "pd.read_sql_query(\"SELECT * FROM publisher2\", connection, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting Data using http/s protocols\n",
    "The first step of collecting web-based data is to issue a request for this data via some protocol: HTTP (HyperText Transfer Protocol) or HTTPS (the secure version).\n",
    "#### using https://docs.python-requests.org/en/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://andyguna.com\")\n",
    "\n",
    "print(\"Status Code:\", response.status_code)   # code = 200 is ok\n",
    "print(\"Headers:\", response.headers)\n",
    "print(response.text[:1000])\n",
    "print(type(response.text))           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Search\n",
    "https://www.google.com/search?q=how+to+break+dance&source=chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "params = {\"query\": \"how to break dance\", \"source\":\"chrome\"}\n",
    "response = requests.get(\"http://www.google.com/search\", params=params)\n",
    "print(response.status_code)\n",
    "response.text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESTful APIs\n",
    "a fair number of web-based data services you will use in practice employ something called REST (Representational State Transfer, but no one uses this term) APIs.\n",
    "API calls - GET, POST, DELETE, PUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find your github access token at https://github.com/settings/tokens/new\n",
    "token = \"????\" \n",
    "response = requests.get(\"https://api.github.com/user\", params={\"access_token\":token})\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.headers[\"Content-Type\"])\n",
    "print(response.json().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "The standard here for a while was called \"Basic Authentication\", and can be used via the requests library by simply passing the login and password as the auth argument to the relevant calls, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://api.github.com/user\", auth=(\"andyguna\", \"github_password\"))\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data Formats\n",
    "Data comes in many different formats, but some of the more common ones that you'll deal with as a data scientist are:\n",
    "CSV, JSON, HTML, XML\n",
    "\n",
    "### CSV Data Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/439_01.csv\", delimiter=\",\", quotechar='\"')\n",
    "df.head(10)\n",
    "df.size\n",
    "print(df.describe())\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json data\n",
    "**data types**\n",
    "Numbers: e.g. 1.0, either integers or floating point, but typically always parsed as floating point\n",
    "Booleans: true or false (or null)\n",
    "Strings: \"string\" characters enclosed in double quotes (the \" character then needs to be escaped as \\\")\n",
    "Arrays (lists): [item1, item2, item3] list of items, where item is any of the described data types\n",
    "Objects (dictionaries): {\"key1\":item1, \"key2\":item2}, where the keys are strings and item is again any data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a jupyter notebook file in its json format\n",
    "# f = open(\"data/Lab 1 - Introduction.ipynb\",\"r\")\n",
    "f = open(\"Week01_Notebook.ipynb\",\"r\")\n",
    "lines = f.readlines()   # output is a list\n",
    "# convert list to string\n",
    "str_text = ' '.join(str(e) for e in lines)\n",
    "str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "y = json.loads(str_text)   #parse the string\n",
    "# y[\"cells\"][0]['source']   # extract the title of the lab\n",
    "# y[\"cells\"][0]['source']   # extract the title of the lab\n",
    "y[\"description\"]        # extract the collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"modules\"]        # extract the collection name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"modules\"][4]['videos'][0]['video_id']     # extract the index 4 the item in the collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"modules\"][4]['videos'][2]['video_id']  # find the video_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dictionary to json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert python dictionary to json object\n",
    "import json\n",
    "data = {\"a\":[1,2,3,{\"b\":2.1}], 'c':4}\n",
    "json.dumps(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\".json\",\"r\")\n",
    "lines = f.readlines()\n",
    "# convert list to string\n",
    "str_text = ' '.join(str(e) for e in lines)\n",
    "y = json.loads(str_text)\n",
    "y[\"collection_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(response)    # types that cannot be represented by json object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XML/HTML\n",
    "\n",
    "<tag attribute=\"value\">\n",
    "    <subtag>\n",
    "        Some content for the subtag\n",
    "    </subtag>\n",
    "    <openclosetag attribute=\"value2\"/>\n",
    "</tag>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tag attribute=\"value\">\n",
    "    <subtag>\n",
    "        Some content for the subtag\n",
    "    </subtag>\n",
    "    <openclosetag attribute=\"value2\"/>\n",
    "</tag>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "root = BeautifulSoup(\"\"\"\n",
    "<tag attribute=\"value\">\n",
    "    <subtag>\n",
    "        Some content for the subtag\n",
    "    </subtag>\n",
    "    <openclosetag attribute=\"value2\"/>\n",
    "    <subtag>\n",
    "        Second one\n",
    "    </subtag>\n",
    "</tag>\n",
    "\"\"\", \"lxml-xml\")\n",
    "\n",
    "print(root, \"\\n\")\n",
    "print(root.tag.subtag, \"\\n\")\n",
    "print(root.tag.openclosetag.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root.tag.find_all(\"subtag\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(root.find_all(\"subtag\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### home page information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing rutgers CS web page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "response = requests.get(\"https://www.cs.rutgers.edu/\")\n",
    "root = BeautifulSoup(response.content, \"lxml\")\n",
    "for div in root.find_all(\"div\", class_=\"custom\"):    # quick links are custom tag\n",
    "    for li in div.find_all(\"li\"):                    # then within li tag\n",
    "        print(li.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing product information\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "URL = \"https://www.newegg.com/p/pl?d=headphones\"\n",
    "html = urlopen(URL)\n",
    "page_str = html.read()\n",
    "html.close()\n",
    "page_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "Any character (except special characters, \".$*+?{}\\[]|() ), just matches itself. I.e., the character a just matches the character a. This is actually what we used previously, where each character in the r\"data science\" regular expression was just looking to match that exact character.\n",
    "\n",
    "Putting a group of characters within brackets [abc] will match any of the characters a, b, or c. You can also use ranges within these brackets, so that [a-z] matches any lower case letter.\n",
    "\n",
    "Putting a caret within the bracket matches anything but these characters, i.e., [^abc] matches any character except a, b, or c.\n",
    "The special character \\d will match any digit, i.e. [0-9]\n",
    "The special character \\w will match any alphanumeric character plus the underscore; i.e., it is equivalent to [a-zA-Z0-9_]\n",
    "The special character \\s will match whitespace, any of [ \\t\\n\\r\\f\\v] (a space, tab, and various newline characters).\n",
    "The special character . (the period) matches any character. In their original versions, regular expressions were often applies line-by-line to a file, so by default . will not match the newline character. If you want it to match newlines, you pass re.DOTALL to the \"flags\" argument of the various regular expression calls.\n",
    ".* any number of characters including zero\n",
    "a+ at least one character {a, aa, aaa, aaaa, ....}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = \"This course will introduce the basics of data science and more Data science\"\n",
    "match = re.search(r\"data science\", text)\n",
    "print(match.start())\n",
    "matches = re.findall(r\"[Dd]ata science\", text)    # returns all matches as a list\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and search\n",
    "regex = re.compile(r\"data science\")\n",
    "regex.search(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple pattern strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower or upper case D and S and \\s space between the two\n",
    "print(re.search(r\"[Dd]ata\\s[Ss]cience\", text))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(r\"[Dd]ata\\s[Ss]cience\", text)    # returns all matches as a list\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping with regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r\"(\\w+)\\s([Ss]cience)\", text)\n",
    "print(match.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(r\"(\\w+)\\s([Ss]cience)\", text)\n",
    "print(match.group(0))\n",
    "print(match.group(1))\n",
    "print(match.group(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub(r\"data science\", r\"data schmience\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(re.sub(r\"(\\w+) ([Ss])cience\", r\"\\1 \\2chmience\", text))\n",
    "print(re.sub(r\"(\\w+) ([Ss])cience\", r\"\\1 \\2chmience\", \"Life Science\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order of operations\n",
    "print(re.match(r\"abc|def\", \"abc\"))\n",
    "print(re.match(r\"abc|def\", \"def\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crazy stuff\n",
    "import re\n",
    "str = \"101\"\n",
    "matches = re.findall(r\".?|(..+?)\\\\1+\", str)    # returns all matches as a list\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @ Copyright 2023  A.D. Gunawardena"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
